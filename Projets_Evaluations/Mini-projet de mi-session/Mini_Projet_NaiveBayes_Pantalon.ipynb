{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9da1c3d3",
   "metadata": {},
   "source": [
    "\n",
    "# Mini‚Äëprojet ‚Äî Classifieur Bay√©sien Na√Øf (Bernoulli) üß†üßÆ\n",
    "\n",
    "> **Math√©matiques pour l'informatique ‚Äî FSGA / Universit√© Quisqueya**  \n",
    "> **Enseignant : Geovany Batista Polo LAGUERRE ‚Äî Semestre 1 ‚Äî 2025‚Äì2026**\n",
    "\n",
    "**Objectif.** Impl√©menter un pipeline simple de classification **Na√Øve Bayes Bernoulli** pour des **mots‚Äëcl√©s binaires** et l'utiliser pour d√©cider d'envoyer une publicit√© √† partir d'une requ√™te contenant le mot *¬´ pantalon ¬ª*.  \n",
    "**Important :** le **lissage de Laplace** est **d√©j√† impl√©ment√©** pour vous dans la classe fournie. Vous devez **l'utiliser** et en **interpr√©ter** l'effet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d7a3b6",
   "metadata": {},
   "source": [
    "\n",
    "## R√®gles & rendu\n",
    "- Travail **individuel**. Autoris√©s : `csv`, `math`, `collections`, `itertools`, `random`, `matplotlib` (facultatif). **Interdit :** `scikit-learn`.\n",
    "- Rendez ce notebook **ex√©cut√©** (toutes les sorties pr√©sentes).  \n",
    "- Nommez le fichier : `NOM_Prenom_NaiveBayes_Pantalon.ipynb`.\n",
    "\n",
    "### Bar√®me (rappel)\n",
    "- Impl√©mentation correcte (utilisation de la classe + pipeline) ‚Äî 35 pts  \n",
    "- Lissage de Laplace **utilis√©** et **interpr√©t√©** ‚Äî 15 pts  \n",
    "- D√©nombrements & fr√©quences affich√©s ‚Äî 15 pts  \n",
    "- D√©mo et cas tests pertinents ‚Äî 15 pts  \n",
    "- Qualit√© du code & commentaires ‚Äî 10 pts  \n",
    "- Analyse & limites/pistes ‚Äî 10 pts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7bd00f",
   "metadata": {},
   "source": [
    "\n",
    "## Donn√©es (jouet)\n",
    "Nous utilisons un jeu **binaire** minimal avec deux mots‚Äëcl√©s¬†: `pas_cher` et `anglais`, et la cible `achat ‚àà {OUI, NON}`.\n",
    "\n",
    "üëâ La cellule suivante **√©crit** le CSV sur votre environnement et l‚Äô**affiche**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022a4e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv, os, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "csv_path = Path(\"/mnt/data/train_pantalon.csv\")\n",
    "rows = [\n",
    "    {\"id\":1, \"pas_cher\":1, \"anglais\":0, \"achat\":\"OUI\"},\n",
    "    {\"id\":2, \"pas_cher\":0, \"anglais\":1, \"achat\":\"NON\"},\n",
    "    {\"id\":3, \"pas_cher\":0, \"anglais\":1, \"achat\":\"NON\"},\n",
    "    {\"id\":4, \"pas_cher\":0, \"anglais\":1, \"achat\":\"NON\"},\n",
    "    {\"id\":5, \"pas_cher\":1, \"anglais\":0, \"achat\":\"NON\"},\n",
    "    {\"id\":6, \"pas_cher\":1, \"anglais\":1, \"achat\":\"OUI\"},\n",
    "    {\"id\":7, \"pas_cher\":1, \"anglais\":0, \"achat\":\"OUI\"},\n",
    "    {\"id\":8, \"pas_cher\":1, \"anglais\":0, \"achat\":\"OUI\"},\n",
    "]\n",
    "\n",
    "csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"id\",\"pas_cher\",\"anglais\",\"achat\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"Fichier √©crit :\", csv_path)\n",
    "    display(df)\n",
    "except Exception as e:\n",
    "    print(\"Fichier √©crit :\", csv_path, \"| pandas indisponible (affichage brut)\")\n",
    "    with open(csv_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        print(f.read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21a8332",
   "metadata": {},
   "source": [
    "\n",
    "## Classe fournie : `NaiveBayesBernoulli` (lissage de **Laplace** d√©j√† impl√©ment√©)\n",
    "- **√Ä VOUS** d‚Äô**utiliser** cette classe dans le pipeline (chargement, fit, pr√©diction, affichage des comptes, etc.).\n",
    "- Vous pouvez ajouter de **nouvelles features binaires** (facultatif).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047d5337",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "from collections import Counter, defaultdict\n",
    "from math import log, exp\n",
    "\n",
    "class NaiveBayesBernoulli:\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = float(alpha)\n",
    "        self.classes_ = []\n",
    "        self.features_ = []\n",
    "        self.class_counts_ = Counter()\n",
    "        self.feature_counts_ = defaultdict(lambda: Counter())\n",
    "        self.n_ = 0\n",
    "\n",
    "    def fit(self, X_list, y_list):\n",
    "        self.n_ = len(y_list)\n",
    "        self.classes_ = sorted(set(y_list))\n",
    "        feat = set()\n",
    "        for X in X_list:\n",
    "            feat |= set(X.keys())\n",
    "        self.features_ = sorted(feat)\n",
    "        self.class_counts_.clear()\n",
    "        self.feature_counts_.clear()\n",
    "        for X, y in zip(X_list, y_list):\n",
    "            self.class_counts_[y] += 1\n",
    "            for f in self.features_:\n",
    "                v = int(X.get(f, 0))\n",
    "                self.feature_counts_[y][(f, v)] += 1\n",
    "        return self\n",
    "\n",
    "    def _p_class(self, c):\n",
    "        return self.class_counts_[c] / self.n_\n",
    "\n",
    "    def _p_feat_given_class(self, feat, val, c):\n",
    "        c1 = self.feature_counts_[c][(feat, 1)]\n",
    "        c0 = self.feature_counts_[c][(feat, 0)]\n",
    "        tot = c1 + c0\n",
    "        num = (c1 + self.alpha) if val == 1 else (c0 + self.alpha)\n",
    "        den = tot + 2*self.alpha\n",
    "        return num / den\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        scores = {}\n",
    "        for c in self.classes_:\n",
    "            s = log(self._p_class(c))\n",
    "            for f in self.features_:\n",
    "                v = int(X.get(f, 0))\n",
    "                s += log(self._p_feat_given_class(f, v, c))\n",
    "            scores[c] = s\n",
    "        m = max(scores.values())\n",
    "        exps = {c: exp(v - m) for c, v in scores.items()}\n",
    "        Z = sum(exps.values())\n",
    "        return {c: exps[c]/Z for c in self.classes_}\n",
    "\n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "        return max(proba, key=proba.get)\n",
    "\n",
    "def load_csv_binary(path, feature_names=(\"pas_cher\",\"anglais\")):\n",
    "    X_list, y_list = [], []\n",
    "    with open(path, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        for row in csv.DictReader(f):\n",
    "            X = {feat: int(row[feat]) for feat in feature_names}\n",
    "            y = row[\"achat\"].strip()\n",
    "            X_list.append(X); y_list.append(y)\n",
    "    return X_list, y_list\n",
    "\n",
    "def pretty_counts(nb: NaiveBayesBernoulli):\n",
    "    print(\"Classes :\", nb.classes_)\n",
    "    print(\"Features:\", nb.features_)\n",
    "    for c in nb.classes_:\n",
    "        print(f\"\\nClasse {c} (count={nb.class_counts_[c]})\")\n",
    "        for f in nb.features_:\n",
    "            c1 = nb.feature_counts_[c][(f,1)]\n",
    "            c0 = nb.feature_counts_[c][(f,0)]\n",
    "            tot = c1 + c0\n",
    "            p1 = (c1 + nb.alpha) / (tot + 2*nb.alpha)\n",
    "            p0 = (c0 + nb.alpha) / (tot + 2*nb.alpha)\n",
    "            print(f\"  {f}: #1={c1}, #0={c0}, p(1|{c})={p1:.3f}, p(0|{c})={p0:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ae4fcb",
   "metadata": {},
   "source": [
    "\n",
    "## TODO 1 ‚Äî Charger les donn√©es et entra√Æner le mod√®le\n",
    "1. Charger `train_pantalon.csv` avec `load_csv_binary`.  \n",
    "2. Cr√©er `NaiveBayesBernoulli(alpha=1.0)` et appeler `fit`.  \n",
    "3. Afficher les **comptes** et **probabilit√©s liss√©es** via `pretty_counts`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d37a9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === VOTRE CODE (TODO 1) ======================================================\n",
    "X_train, y_train = load_csv_binary(\"/mnt/data/train_pantalon.csv\", feature_names=(\"pas_cher\",\"anglais\"))\n",
    "nb = NaiveBayesBernoulli(alpha=1.0).fit(X_train, y_train)\n",
    "pretty_counts(nb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38c70ea",
   "metadata": {},
   "source": [
    "\n",
    "## TODO 2 ‚Äî Pr√©dire et interpr√©ter\n",
    "1. Calculer `predict_proba` et `predict` pour les cas : [1,1], [1,0], [0,1], [0,0].  \n",
    "2. **Comparer** avec/sans lissage (`alpha=0` vs `alpha=1`).  \n",
    "3. En 4‚Äì6 lignes : **interpr√©ter** l‚Äôeffet du lissage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada9e955",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === VOTRE CODE (TODO 2) ======================================================\n",
    "tests = [\n",
    "    {\"pas_cher\":1, \"anglais\":1},\n",
    "    {\"pas_cher\":1, \"anglais\":0},\n",
    "    {\"pas_cher\":0, \"anglais\":1},\n",
    "    {\"pas_cher\":0, \"anglais\":0},\n",
    "]\n",
    "\n",
    "def run_preds(alpha):\n",
    "    nb = NaiveBayesBernoulli(alpha=alpha).fit(X_train, y_train)\n",
    "    out = []\n",
    "    for x in tests:\n",
    "        proba = nb.predict_proba(x)\n",
    "        yhat = nb.predict(x)\n",
    "        out.append((x, proba, yhat))\n",
    "    return out\n",
    "\n",
    "print(\"== Avec lissage alpha=1.0 ==\")\n",
    "for x, proba, yhat in run_preds(1.0):\n",
    "    print(x, \"‚Üí\", yhat, \"| proba:\", {k:round(v,3) for k,v in proba.items()})\n",
    "\n",
    "print(\"\\n== Sans lissage alpha=0.0 ==\")\n",
    "for x, proba, yhat in run_preds(0.0):\n",
    "    print(x, \"‚Üí\", yhat, \"| proba:\", {k:round(v,3) for k,v in proba.items()})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae772ad",
   "metadata": {},
   "source": [
    "\n",
    "## TODO 3 ‚Äî Ajouter une ou deux features (facultatif, recommand√©)\n",
    "- Proposer une nouvelle variable binaire (ex. `promo`, `dispo`, `marque`) et **√©tendre le CSV**.  \n",
    "- R√©entra√Æner et commenter l‚Äôimpact sur les pr√©dictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f43719",
   "metadata": {},
   "source": [
    "\n",
    "## TODO 4 ‚Äî Rapport court (5‚Äì8 lignes)\n",
    "- Hypoth√®se **na√Øve** (ind√©pendance conditionnelle **√† classe fix√©e**).  \n",
    "- Pourquoi elle est pratique (et sa **limite**).  \n",
    "- Interpr√©ter l‚Äôeffet du **lissage** √† partir de vos r√©sultats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4373018",
   "metadata": {},
   "source": [
    "\n",
    "## (Option) Visualisation simple\n",
    "Carte des scores en fonction de `pas_cher` et `anglais`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf34522",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# OPTIONNEL : visualiser p(OUI | pas_cher, anglais)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "nb = NaiveBayesBernoulli(alpha=1.0).fit(X_train, y_train)\n",
    "\n",
    "grid = [(a,b) for a in [0,1] for b in [0,1]]\n",
    "scores = []\n",
    "for a,b in grid:\n",
    "    proba = nb.predict_proba({\"pas_cher\":a,\"anglais\":b})\n",
    "    scores.append(proba[\"OUI\"])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,3))\n",
    "im = ax.imshow(np.array(scores).reshape(2,2), vmin=0, vmax=1, origin=\"lower\")\n",
    "ax.set_xticks([0,1]); ax.set_xticklabels([\"anglais=0\",\"anglais=1\"])\n",
    "ax.set_yticks([0,1]); ax.set_yticklabels([\"pas_cher=0\",\"pas_cher=1\"])\n",
    "for i,(a,b) in enumerate(grid):\n",
    "    ax.text(b, a, f\"{scores[i]:.2f}\", ha=\"center\", va=\"center\", color=\"w\")\n",
    "ax.set_title(\"p(OUI | pas_cher, anglais) ‚Äî alpha=1\")\n",
    "fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
